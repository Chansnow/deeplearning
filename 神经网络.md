# 神经网络

##### 神经网络优点

对所有的问题都可以用同样的流程来解决

##### 神经网络学习的目的

以损失函数为基准，找出能使它的值达到最小的权重参数

##### 机器学习的终极目标

获得泛化能力防止过拟合（只对某个数据集过度拟合）

---

#### 损失函数

表示神经网络性能的恶劣程度的指标

常用的有**均方误差**和**交叉熵误差**

##### 均方误差

单个数据的损失函数: $E=\frac{1}{2}\sum_k(y_k-t_k)^2$

> $y_k$表示神经网络的输出， $t_k$为监督数据，k为数据的维数

所有数据的平均损失函数: $E=\frac{1}{2n}\sum_n\sum_k(y_{nk}-t_{nk})^2$

##### 交叉熵误差

单个数据的损失函数: $E=-\sum_kt_k\log{y_k}$

```在具体编程时常使用``` $E=-\sum_kt_k\log{(y_k+\delta)}$```加上微小值作为保护，防止log0出现负无穷```

> 实际上只计算对应正确解标签的输出的对数（ $t_k$使用one-hot独热编码表示），即交叉熵误差的值是有正确解标签对应的输出结果决定

所有数据的平均损失函数: $E=-\frac{1}{n}\sum_n\sum_kt_{nk}\log{y_{nk}}$

##### 为何需要设定损失函数

因为如果以识别精度为指标，则参数的导数在绝大多数地方都会变为0

> 识别精度对微小参数变化基本上不会有什么反应（改变微小参数，识别精度可能仍然保持不变），即便有反应它的值也是不连续地、突然地变化


